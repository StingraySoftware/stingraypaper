% This document is part of the transientdict project.
% Copyright 2013 the authors.

\documentclass[12pt]{emulateapj}
\usepackage{xspace}
\usepackage{graphicx}
%\usepackage{epsfig}
\usepackage{times}
\usepackage{natbib}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amsbsy}
\usepackage{bm}
\usepackage{hyperref}
\usepackage{url}
%\usepackage{subfigure}
\usepackage{microtype}
\usepackage{rotating}
\usepackage{booktabs}
\usepackage{threeparttable}
\usepackage{tabularx}
\usepackage{subfigure}
\usepackage{minted}


%\usepackage{longtable}%\usepackage[stable]{footmisc}
%\usepackage{color}
%\bibliographystyle{apj}

% MB: I added xspace so that we don't have to use '\ ' after the commands
% For commands that may or may not stay inside a math environment, we can 
% also use \ensuremath
\newcommand{\project}[1]{\textsl{#1}\xspace}
\newcommand{\fermi}{\project{Fermi}\xspace}
\newcommand{\rxte}{\project{RXTE}\xspace}
\newcommand{\given}{\ensuremath{\,|\,}}
\newcommand{\dd}{\ensuremath{\mathrm{d}}}
\newcommand{\counts}{\ensuremath{y}}
\newcommand{\pars}{\ensuremath{\theta}}
\newcommand{\mean}{\ensuremath{\lambda}}
\newcommand{\likelihood}{\ensuremath{{\mathcal L}}}
\newcommand{\Poisson}{\ensuremath{{\mathcal P}}}
\newcommand{\Uniform}{\ensuremath{{\mathcal U}}}
\newcommand{\bg}{\ensuremath{\mathrm{bg}}}
\newcommand{\word}{\ensuremath{\phi}}
\newcommand{\zsq}{\ensuremath{Z^2_n}}
\newcommand{\stingray}{\texttt{stingray}\xspace}
\newcommand{\maltpynt}{\texttt{whatever-name-ex-maltpynt-gets}\xspace}
\newcommand{\python}{\texttt{Python}\xspace}
\newcommand{\astropy}{\texttt{astropy}\xspace}
\newcommand{\lightcurve}{\texttt{Lightcurve}\xspace}
\newcommand{\eventlist}{\texttt{EventList}\xspace}
\newcommand{\crossspectrum}{\texttt{Crossspectrum}\xspace}
\newcommand{\powerspectrum}{\texttt{Powerspectrum}\xspace}

\newcommand{\hendrics}{\texttt{HENDRICS}\xspace}
\newcommand{\dave}{\texttt{DAVE}\xspace}


%\newcommand{\bs}{\boldsymbol}

\begin{document}

\title{\stingray: A modern \python\ Library For Spectral Timing}

\author{D. Huppenkothen\altaffilmark{1, 2, 3}, M. Bachetti\altaffilmark{4}, A. Stevens\altaffilmark{}, OTHER CO-AUTHORS!}
 
\altaffiltext{1}{Center for Cosmology and Particle Physics, Department of Physics, New York University, 4 Washington Place, New York, NY 10003, USA \\
}
  \altaffiltext{2}{Center for Data Science, New York University, 65 5h Avenue, 7th Floor, New York, NY 10003}
  \altaffiltext{3}{E-mail: daniela.huppenkothen@nyu.edu}
\altaffiltext{4}{INAF-Osservatorio Astronomico di Cagliari, via della Scienza 5, I-09047 Selargius (CA), Italy}
\altaffiltext{5}{}
\altaffiltext{}{}
\altaffiltext{}{}


\begin{abstract}
% This abstract could be more exciting, I think.
This paper describes the design, implementation and usage of \stingray, a library in \python built to perform time series analysis and related tasks on astronomical light curves. 
Its core functionality comprises a large range of Fourier analysis techniques commonly used in Spectral Timing, as well as extensions for analysing pulsar data, simulating data sets, and statistical modelling. 
Its modular build allows for easy extensions and we aim for the library to be a platform for future development. 
Here, we describe its Python classes and functions in detail, as well as give practical example using astronomical data sets. 
The code is well-tested, with a test coverage of currently 95\%.

\end{abstract}

\keywords{methods:statistics}

\section{Introduction}

Variability is one of the key diagnostics in understanding the underlying physics of the dynamics and emission processes from astronomical objects. 
The detection of periodic variations in the radio flux of certain objects has led to the ground-breaking discovery of pulsars. Similarly, accurately describing of dips in stellar light curves has led to the discovery of thousands of exoplanets. 
In high-energy astrophysics, particularly the study of black holes and neutron stars, the scientific developments of recent years have brought a growing understanding that time and wavelength are intricately linked. 
Different spectral components react differently to changes in accretion rate and dynamics, leading to time lags, correlated variability and higher-order effects. 
This has led to the study of accretion disks, in particular those of Active Galactic Nuclei (AGN), via reverberation mapping. 
Understanding how the emission at various wavelengths changes with time is crucial for testing and expanding our understanding of General Relativity in the strong gravity limit, the dense matter equation of state and other fundamental questions in astrophysics.

\section{Vision}

Despite decades of research, the field is fragmented in terms of software; there is no commonly accepted, up-to-date framework for the core data analysis tasks involved in (spectral) timing. Code is generally siloed within groups, leading to a general lack of reproducibility of scientific results. Additionally, the lack of fully open-source tools constitutes a significant barrier to entry for researchers new to the field, since it effectively requires anyone not part of collaborations with an existing private code base to write their own software from scratch. 
The NASA library \texttt{xronos} is, to our knowledge, the only significant open-source library in this field, and has several shortcomings. 
In particular, it performs only a few of the most basic tasks, and it has not been maintained since 2004. 
Here, we introduce \stingray, a lightweight library built entirely in \python and based on \astropy functionality, to address the lack of well-tested, well-documented software for spectral timing. 
\stingray aims to make many of the core Fourier analysis tools used in timing analysis available to a large range of researchers while providing a common platform for new methods and tools as they enter the field. 
It includes the most relevant functionality in its core package, while extending that functionality in its subpackages in several ways, allowing for easy modeling of light curves and power spectra, simulation of synthetic data sets and pulsar timing. 

Its primary idea is to provide time series analysis methods in an accessible, well-tested way, built as a series of modules in an object-oriented way. In practice, data 
analysis requirements are varied and depend on the type of data, the wavelength the observation was taken at, and the object being observed. With this in mind, 
\stingray does not aim to provide full data analysis workflows; rather, it provides the core building blocks for users to build such workflows themselves, based on the specific data analysis requirements of their source and observation. 
The modularity of its classes allows for easy incorporation of existing \stingray functionality into larger data analysis workflows and pipelines, while being easily extensible for cases that the library currently does not cover. 

\stingray is designed to be used both as a standalone package, but is also at the core of two other software packages currently under development: \hendrics [REF] provides pre-built data analysis workflows using \stingray core functionality. These workflows are accessible from the command line and are provided for some common data types and data analysis tasks. \dave [REF] on the other hand, provides a Graphical User Interface on top of \stingray to allow for easy interactive exploratory data analysis.
 
As of v0.1, it includes basic functionality depends exclusively on \texttt{numpy} [REF], \texttt{scipy}[REF] and \texttt{astropy}[REF], with optional plotting functionality supplied by \texttt{matplotlib}[REF] and optional sampling methods by \texttt{emcee}[REF]. [ADD OTHER OPTIONAL DEPENDENCIES HERE!].

This paper describes \stingray v0.1, released on 2018-02-12. 
As with most open-source packages, \stingray is under continuous development and welcomes contributions from the community.
The paper layout is as follows: 
In Section \ref{sec:general_package}, we describe the general package structure. 
In Section \ref{sec:core}, we detail the package's core functionality in Fourier analysis and introduce basic classes for storing light curves and Fourier spectra of various types. 
In Section \ref{sec:modeling}, we extend this core functionality with \stingray's modeling framework and in Section \ref{sec:simulator}, we show how users can easily simulate data sets from models. 
Sections \ref{sec:pulsar} lays out the functionality for analysing pulsar data, and Section{ref:dave} details existing connections to a graphical user interface currently being developed in parallel to \stingray. 
Finally, in Sections \ref{sec:development} and \ref{sec:future} we lay out the development process, testing and documentation environments as well as our future development plans. 
In each section, we present examples of the functionality described based on real-world data sets.

\section{General Package Framework}
\label{sec:general_package}

\stingray separates out core functionality from several more specialized tasks based on those core classes and functions. Constructs related to data products as well as transformations of the data (e.g.\ power spectra, cross spectra, time lags, and other spectral timing products) are considered core functionality, as are some utility functions and classes, for example related to Good Time Interval calculations. 

Current functionality in subpackages includes a framework to allow for the parametric modelling of light curves and Fourier products, simulations of spectral timing products from power spectra, and period searches in pulsars.


\section{Core Functionality}
\label{sec:core}

\stingray imports its core functions and classes from the top level package. 
These classes define the basic data structures such as light curves and cross- as well as power spectra that are used in much of the higher-level functionality provided in the sub-packages. 
Additionally, it incorporates a large range of utilities for dealing with Good Time Intervals (GTIs) as well as input and output of data sets. 

\subsection{The \texttt{Lightcurve} class}
\label{sec:lightcurve}

We expect \stingray to be used largely on data sets of two forms: (1) event data (i.e. recordings of arrival times of individual photons) or (2) binned light curves. 
The majority of methods in \stingray use binned light curves, which we thus currently consider the default format. The \lightcurve class defines a basic data structure to store binned light curves. For binned data, the class can simply be invoked supplying time stamps and the corresponding flux values (and optionally uncertainties on the flux measurements):

\begin{minted}{python}
lc = Lightcurve(time, counts, err, 
		       input_counts=True, 
		       gti=None, 
		       err_dist='poisson', 
		       mjdref=0, dt=None)
\end{minted}

where \texttt{counts} corresponds to the flux per bin (or the number of photon counts per bin in the photon counting case), \texttt{err} are the flux uncertainties and \verb|input_counts| should be set to \texttt{True} if the input is in flux per bin (as opposed to flux per second). While it is possible to input GTIs, they will not by default be applied to the light curve itself, but propagated to classes and functions that take \lightcurve objects as input and make use of the GTIs stored in the object. There is, however, a method that splits a light curve into several \lightcurve objects, one for each contiguous good time interval. For unevenly sampled data or cases where gaps exist in the data, the internal algorithm for determining the time resolution \texttt{dt} might not always be correct; in these cases, it can help to input a reference time resolution manually.

For event data, a static method exists that will take the time stamps of events as well as a time resolution and create a light curve using \texttt{numpy.histogram}:

\begin{minted}{python}
lc = make_lightcurve(toa, dt, tseg=None, 
		     tstart=None, 
		     gti=None,
		     mjdref=0,
		     use_hist=False)
\end{minted}

Here, \texttt{toa} should be a list or array of times of arrivals of the events and \texttt{dt} the time resolution of the binned light curve. By default, the light curve start with the arrival of the first photon and end with the arrival of the last photon. Optionally, if the observation or segment begins before the arrival time of the first event and/or ends after the arrival time of the last event, one may optionally include a start time \texttt{tstart} and a total duration \texttt{tseg} for the creation of the regular time grid. 

Beyond providing a basic data structure for light curves and a creation mechanism out of event data, \stingray implements a range of operations acting on these objects. It overrides several standard operations such as the \texttt{+} operator \verb|__add__| and the \texttt{-} operator \verb|__sub__|, allowing to efficiently add and subtract light curves from one another. In either case, the addition and subtraction will operate on the \texttt{counts} attribute, and derivative attributes such as \verb|count_rate| and \texttt{err} will be automatically be recalculated. Similarly overloaded operations are the built-in function \verb|__len__|, which will return the number of time bins in the light curve, and \verb|__neg__|, which will invert the values in the \texttt{counts} attribute.

Other functionality on light curves includes rebinning to a new time resolution, which must be lower than the previous time resolution (i.e.\ interpolation is not implemented). 
\lightcurve objects can also be joined, truncated and sorted by time or counts. Finally, \stingray implements basic methods for plotting (useful for a quick look at the data), as well as reading and writing into various formats (currently FITS, HDF5 and ASCII).

\subsection{The \texttt{Events} class}

At short wavelengths, data is largely recorded as \textit{photon events}, where arrival times at the detector are recorded for each photon independently, along with a number of other properties of the event (for example an energy channel in which the photon was recorded in, which can be transformed to a rough estimate of the energy of the original photon arriving at the detector).

\stingray implements a basic class \eventlist that acts as a container for data sets of these types. Even for a single instrument, there are often multiple data formats and types of data recorded, resulting in a plethora of data formats and internal schema to how data is stored within the FITS files distributed to the community. 
\stingray implements a basic \eventlist class that acts as a container for basic event data, but does not aim to encompass all current data types of all current (and future) instruments entirely. Instead, it aims to abstract away from instrument-specific idosyncrasies as much as possible and remain mission-agnostic. In its basic form, it takes arrays with time stamps and optionally corresponding photon energies as input, and implements a set of basic methods. Similarly to \lightcurve, it provides basic input/output (I/O) functionality in the form of \texttt{read} and \texttt{write} methods as well as a method to join event lists, which can be particularly useful when data is recorded in several independent detector, as is common for several current and future X-ray missions. The \verb|to_lc| method provides straightforward connection to create a \lightcurve directly out of an \eventlist object. In return, it is possible to create an \eventlist out of a \lightcurve object using the \verb|from_lc|. The latter will create $N_i$ events, each with a time stamp equation to the time bin $t_i$, where $N_i$ is the number of counts in bin $i$ (event lists are, by their very definition only a useful data product if the light curve used to simulate comes from photon counting data in the first place). 
It is possible to simulate more physically meaningful photon events from a given light curve and energy spectrum using the \verb|simulate_times| and \verb|simulate_energies| methods, which employ a combination of interpolation and rejection sampling to accurately draw events from the given light curve and spectrum.


\subsection{Cross Spectra and Power Spectra}
\label{sec:csps}

[TODO: ADD SOME CODE AND EXAMPLE PLOTS]

Consider two independently distributed, evenly-sampled, stationary time series,

\begin{eqnarray}
\mathbf{x} &=& \{x_k\}_{k=1}^N \nonumber \\
\mathbf{y} &=& \{y_k\}_{k=1}^N \nonumber
\end{eqnarray}

\noindent with $N$ data points taken at simultaneous time intervals $\{t_k\}_{k=1}^N$ with a constant time resolution $\Delta t$ and a total duration $T = N\Delta t$. 
The data points in the time series $\mathbf{x}$ and $\mathbf{y}$ can be expressed in terms of a Fourier series,

\begin{eqnarray}
x_k & = & \frac{1}{N} \sum_{j}{\mathcal{F}_x(j)} \nonumber \\
x_y & = & \frac{1}{N} \sum_{j}{\mathcal{F}_y(j)}
\end{eqnarray}

\noindent where

\begin{eqnarray}
\mathcal{F}_x(j) &= & \frac{1}{2} (A_{xj} - i B_{xj}) e^{-i\left( \frac{2 \pi j t}{T} \right)} \\
\mathcal{F}_y(j) &= & \frac{1}{2} (A_{yj} - i B_{yj}) e^{-i\left( \frac{2 \pi j t}{T} \right)} \, .
\end{eqnarray}

\noindent Here, $i = \sqrt{-1}$, and $A_{xj}, A_{yj}$ and $B_{xj}, B_{yj}$ describe the real and imaginary parts of the Fourier amplitudes, respectively (for a pedagogical introduction into Fourier analysis, see \citealt{vanderklis1989}). We restrict $\mathcal{F}_x(j)$ and $\mathcal{F}_y(j)$ to frequencies between $\nu_{j=0} = 1/T$ and the Nyquist frequency $\nu_{j=N/2} = 1/(2\Delta t)$.
The complex cross spectrum is then calculated by multiplying the Fourier transform of light curve $\mathbf{x}$ with the complex conjugate of the Fourier transform of light curve $\mathbf{y}$ (\citealt{vaughan1997,nowak1999}, see also \citealt{uttley2014} for a recent review of spectral timing techniques):

\begin{eqnarray}
\mathcal{F}_x(j) \mathcal{F}_y^*(j) & = & \frac{1}{2} (A_{xj} - i B_{xj}) e^{i \frac{2 \pi j t}{T}} \frac{1}{2} (A_{yj} + i B_{yj}) e^{i \frac{-2 \pi j t}{T}}\nonumber \\ 
		     & = & \frac{1}{4} [ (A_{xj}A_{yj} + B_{xj}B_{yj}) + \\\nonumber
		     & &  i (A_{xj}B_{yj} - A_{yj}B_{xj}) ]
\end{eqnarray}

Note that for strictly real-valued time series, as light curves in astronomy always are, $A_j = A_{-j}$ and $B_j = - B_{-j}$, such that 

\begin{equation}
\mathcal{F}_x(j) \mathcal{F}_y^*(j) = \frac{1}{2} \left\{ (A_{xj}A_{yj} + B_{xj}B_{yj}) + i (A_{xj}B_{yj} - A_{yj}B_{xj}) \right\} \, .
\label{eqn:crossspectrum}
\end{equation}

This is the formal definition of the cross spectrum, implemented in class \crossspectrum. Its inputs are two \lightcurve object, as well as optionally a normalization for the resulting Fourier amplitudes, and an array of GTIs. As defined above, it will compute the Fourier amplitudes $A_{xj}, A_{yj}$ and $B_{xj}, B_{yj}$ and store the complex result of Equation \ref{eqn:crossspectrum} in an attribute \texttt{power} along with the corresponding mid-bin frequencies in a second attribute \texttt{freq}.

The power spectrum\footnote{TEXT ABOUT DIFFERENCE BETWEEN POWER SPECTRUM AND PERIODOGRAM} can be formulated as the special case of the cross spectrum where $\mathbf{x} = \mathbf{y}$, i.e.\ the cross spectrum of a light curve with itself. The class \powerspectrum is hence implemented as a subclass of \crossspectrum and takes only one \lightcurve object instead of two. The squared amplitudes corresponding to Equation \ref{eqn:crossspectrum} become in this case

\begin{equation}
\mathcal{F}_x(j) \mathcal{F}_x^*(j) = \frac{1}{2} \left\{ (A_{xj}A_{xj} + B_{xj}B_{xj})\right\} \, .
\end{equation}

\noindent The imaginary part of Equation \ref{eqn:crossspectrum} cancels out for the power spectrum, since the Fourier amplitudes come from identical light curves, and thus the phase difference between them is exactly $0$. 

There are several popular normalizations for the real part of the cross spectrum as well as the power spectrum implemented in \stingray: the popular Leahy normalization [REF] is defined as 

\begin{equation}
P_j = \frac{2}{\sqrt{N_{p,x}N_{p,y}}} C_j \; ,
\end{equation}

\noindent where  $N_{p,x}^2$ and $N_{p,y}^2$ denote the total number of counts in light curves $\mathbf{x}$ and $\mathbf{y}$, respectively, and $C_j =  (A_{xj}A_{yj} + B_{xj}B_{yj}) $ as defined in Equation \ref{eqn:crossspectrum} above. As shown in [REF], this normalization allows for straightforward period searches in white noise cross spectra and power spectra, and can be applied when creating a \crossspectrum or \powerspectrum object by setting the keyword \verb|norm="leahy"|. 

Another common way to normalize the cross spectrum is such that the integral under the powers corresponds to the fraction of the total variance of the light curve contained between the lower and upper integration bound in frequency space. This rms normalization [REF] is defined as

\begin{equation}
P_j = \frac{2 T_\mathrm{seg}}{N^2 \mu_{xy}^2} C_j \; ,
\end{equation}

\noindent where $C_j$ is defined as above, $N = N_x = N_y$ is the number of time bins in the light curves, $T_\mathrm{seg}$ denotes the total length in time of the light curve, and the total mean count rate is defined as $\mu_{xy} = \sqrt{\mu_x \mu_y}$ in terms of the mean count rate in each light curve $\mu_x$ and $\mu_y$. This normalization can be accessed using the \verb|norm="frac"| keyword. Closely related is the absolute rms normalization (\verb|norm="abs"|, which calculates the powers such that the integral between two frequencies $\nu_\mathrm{low}$ and $\nu_\mathrm{high}$ corresponds to the total variance contained between those frequencies:

\begin{equation}
P_j = \frac{2 T_\mathrm{seg}}{N^2} C_j \; .
\end{equation}

\noindent Setting the keyword argument \verb|norm="none"| will return the unnormalized powers $C_j$. The classes \crossspectrum and \powerspectrum share most of the implemented methods, except where otherwise noted. Both classes include methods to rebin cross- and power spectra. Linear rebinning is implemented analogously to the method in class \lightcurve. Additionally, logarithmic binning is implemented in the method \verb|rebin_log| in such a way that the bin width at a given frequency increases a fraction of the previous bin width:

\[
d\nu_{i+1} = d\nu_{i} (1 + f) \; ,
\]

\noindent where $f$ is some constant factor by which the frequency resolution increases, often $f = 0.01$. 

In the case of the cross spectrum, it is also possible to calculate the time lag, defined as

\[
\tau_j = \frac{\phi_j}{2\pi\nu_j} \; 
\]

\noindent for a phase angle $\phi_j$ derived from the imaginary component of the complex cross spectrum, $(A_{xj}B_{yj} - A_{yj}B_{xj})$ and a mid-bin frequency $\nu_j$. Similarly, it is possible to calculate the coherence [REF] from the cross spectrum, defined as 

\begin{equation}
c_j = \frac{C_{xy,j}}{C_{x,j} C_{y,j}} \; . 
\end{equation}

\noindent Here, $C_{xy,j}$ corresponds to the real part of the unnormalized cross spectrum defined in Equation \ref{eqn:crossspectrum}, and $C_{x,j}$ and $C_{y,j}$ correspond to the analogous squared amplitudes of the power spectrum for each individual light curve. 

Classical period searches are often formulated as outlier detection problems from an expected statistical distribution. Assuming the signal is sufficiently coherent such that all of the signal power is concentrated in one bin, one may calculate the chance probability that an observed power was generated by statistical fluctuations alone. The distribution for power spectra is well known: For a Leahy-normalized spectrum, the powers are distributed following a $\chi^2$ distribution around a mean of $2$ in the case of pure white noise, and following a $\chi^2$ distribution around an underlying power spectral shape for other stationary stochastic processes. In the white noise case, the equations to accurately calculate a $p$-value of rejecting the hypothesis that a given outlier in the power spectrum was generated by white noise was defined in \citep{Groth1975}, and can be calculated for one or multiple powers in a \Powerspectrum object using the \verb|classical_significances| method. The cross spectrum does not follow the same distribution \citep{huppenkothen2018}, and the recently derived statistical distributions for this case will be implemented in a future version of \stingray. 

In many practical applications, users may wish to average power- or cross spectra from multiple light curve segments in order to suppress statistical noise. This can easily be done with the appropriate classes \texttt{AveragedPowerspectrum} and \texttt{AveragedCrossspectrum}, which take a \lightcurve object or list of \lightcurve objects as an input and will compute averaged Fourier products for a given length of segment. Both are subclasses of \crossspectrum, and either inherit or override many of the methods relevant for those classes as well. 



\subsection{Higher-Order Fourier Products}
\label{sec:fourier_others}

\section{The \texttt{modeling} Subpackage}
\label{sec:modeling}

Modelling data sets with parametric (often physically motivated) models that map an independent variable (e.g.\ time or frequency) to one or more dependent variables (e.g.\ flux, counts or Fourier powers) is a common task in astronomy. Constructing a general-purpose modelling framework is a highly non-trivial task, thus \stingray's modelling interface currently restricts itself to models of commonly used spectral-timing products, in particular modelling power spectra. 




\section{The \texttt{simulator} Subpackage}
\label{sec:simulator}

\section{The \texttt{pulse} Subpackage}
\label{sec:pulsar}
\stingray contains the basic operations to perform the search and characterization of pulsed signals.
(...)
\subsection{Folding}
Among the basic algorithms used in pulsar astronomy, one cannot overstate the importance of Epoch Folding (EF).
The algorithm consists of cutting the signal at every pulse period and summing all sub-intervals in phase. 
An alternative way of seeing it, more useful for photon data, is just a \textit {histogram of pulse phases}.

If the period is exactly correct and assuming a stable pulsation, the signal-to-noise ratio will get better approximately with the square root of the number of summed sub-intervals [REF].
This is the method used to obtain practically all pulse profiles shown in the literature, as most pulsar signals are orders of magnitude below noise level.

The `pulse.pulsar` submodule contains the functionality to calculate the phase given a simple pulse ephemeris consisting of any number of pulse frequency derivatives%
\footnote{For more complicated cases, like binary pulsars or long-term pulsar noise not well described by pulse derivatives, we recommend to look at more focused libraries like \href{https://github.com/nanograv/PINT}{PINT} [REF]}.
Moreover, we have a mechanism to calculate the exposure of single bins in the pulse profile. 
This is particularly useful for very long-period pulsars where the pulsed period is comparable to the length of the GTIs.
The different exposure of pulse bins caused by the absence of signals during GTIs is taken into account in the calculation of the final pulse profile by the folding algorithm, if the user asks for it. 

\subsection{Epoch Folding and \zsq search}
\label{sec:efzsq}
During a search for pulsations, the first step is usually the PDS. 
However, often pulsations do not leave a clear signature above noise level in the PDS, because they are weak or they fall close to bin edges, where the sensitivity is reduced [REF].
Even when they do, the frequency resolution of the PDS is often inadequate to measure precisely the pulse frequency.
Therefore, an additional statistical analysis is needed. 
In this Section, we will describe the Epoch Folding search (EFS).
This search method consists of executing the folding at many trial frequencies around the candidate frequency.
Once the folding is performed, the following statistics is calculated on the profile:
\begin{equation}
\mathcal{S} = \sum_i\frac{(P_i - \overline{P})^2}{\sigma^2}
\end{equation}
where $P_i$ are the bins of the profile, $\overline{P}$ is the mean level of the profile, and $\sigma$ is the standard deviation.
This is the \textit{chi squared} of the actual pulsed profile with respect to a \textit{flat} model.

If there is no pulsation, the chi squared will assume a random value distributed around the number of degrees of freedom $n - 1$ (where $n$ is the number of bins in the profile) with a well defined statistical distribution ($\chi^2_{n - 1}$) that allows an easy calculation of detection limits. 
When a peak is \textit{very unlikely} (meaning that the probability to be obtained by noise is below a certain $\epsilon$), this peak is considered a pulse candidate.
If the frequency resolution is sufficiently high, close to the correct frequency, as described by [Leahy et al. 1983, 1987], the peak in the epoch folding periodogram has the shape of a \textbf{sinc squared function} whose width is driven by the length of the observation.

The epoch folding statistics, however, can give the same value for a pulse profile at the correct frequency and, for example, an harmonic that produces a deviation from a Poisson distribution.
A more effective method is the $Z^2_n$ statistics (Buccheri et al. 1983), which is conceptually similar to EF but has high values when the signal is well described by a small number of \textbf{sinusoidal harmonics}: 

\begin{equation}
\zsq = \dfrac{2}{N} \sum_{k=1}^n \left[{\left(\sum_{j=1}^N \cos k \phi_j\right)}^2 + {\left(\sum_{j=1}^N \sin k \phi_j\right)}^2\right]
\end{equation}

Where $N$ is the number of photons, $n$ is the number of harmonics, $\phi_j$ are the phases corresponding to the event arrival times $t_j$ ($\phi_j = \nu t_j$, where $\nu$ is the pulse frequency).

The \zsq statistics defined in this way, far from the pulsed profile, follows a $\chi^2_n$ distribution, where $n$ is the number of harmonics this time.
This allows, again, to easily calculate thresholds based on the probability of obtaining a given \zsq by pure noise.

The standard \zsq search calculates the phase of each photon and calculates the sinusoidal functions above for each photon.
This is very computationally expensive if the number of photons is high. 
Therefore, in Stingray, the search is performed by binning the pulse profile first and using the phases of the folded profile in the formula above, multiplying the squared sinusoids of the phases of the pulse profile by a weight corresponding to the number of photons at each phase.

\begin{equation}
\zsq \approx \dfrac{2}{\sum_j{w_j}} \sum_{k=1}^n \left[{\left(\sum_{j=1}^m w_j \cos k \phi_j\right)}^2 + {\left(\sum_{j=1}^m w_j \sin k \phi_j\right)}^2\right]
\end{equation}

Since the sinusoids are only executed on a small number of bins, while the epoch folding procedure just consists of a very fast histogram-like operation, the speedup of this new formula is obvious. 
Care must be put into the choice of the number of bins, in order to maintain a good approximation even when the number of harmonics is high. 
We recommend in the documentation to use a number of bins at least 10 times larger than the number of harmonics.

\subsection{Characterization of pulsar behavior}
\label{sec:ephem}
As seen in Section~\ref{sec:efzsq}, the \zsq or the EF periodograms of a perfectly stable pulsation have the shape of a sinc squared function.
\stingray has additional functionality to fit these periodograms with sinc squared or Gaussian models, and find the mean frequency with high precision.

A significant deviation from the expected shape from these peaks in the periodogram can happen if the pulsation is not stable.
Calculating the periodogram is an option to investigate how the pulse phase varies in time.
The periodogram is basically a 2-D histogram of the phase and arrival times of the pulses. 
If the pulsation is stable and the pulse frequency was determined with precision, the periodogram shows vertical stripes corresponding to perfectly aligned pulses.
If the frequency is not as precise, the stripes become more and more diagonal.
If the pulse has a detectable frequency derivative, these stripes bend with a parabolic shape.

A very precise way to determine the exact pulse ephemeris is out of the scope of \stingray. 
However, \stingray has a mechanism to calculate the pulse arrival times (or times of arrival, TOAs) using a pulse template, using the \texttt{fftfit} algorithm used for radio pulsars. 
This is implemented in the \verb|get_TOA| function in `stingray.pulse.pulsar`.
Then, the user can use the TOAs with more focused software like Tempo, Tempo2 or PINT.

[Fig. XXXX: a variation of the pulse phase corresponding to a period derivative. ]

\section{Connections to \texttt{DAVE}}
\label{sec:dave}

\section{\maltpynt: command-line interface}
\label{sec:maltpynt}


\section{Development and Integration Environment}
\label{sec:development}

\section{Future Development Plans}
\label{sec:future}

\paragraph{acknowledgements}
DH acknowledges funding from the James Arthur Fellowship at NYU and the Moore-Sloan Data Science Environment at NYU. 
We thank the Lorentz Centre for organizing the workshop that started this collaboration.
\clearpage

\bibliography{stingraypaper}
\bibliographystyle{apj}

\end{document}


